{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70a85a7",
   "metadata": {},
   "source": [
    "# Ø¬Ù„Ø³Ù‡ Û±Ûµ: Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ ØªØ±Ø¬Ù…Ù‡ Ùˆ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ØªÙ† Word Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337764e",
   "metadata": {},
   "source": [
    "\n",
    "ğŸ¯ **Ù‡Ø¯Ù:**  \n",
    "Ø¯Ø± Ø§ÛŒÙ† Ø¬Ù„Ø³Ù‡ Ø¨Ø§ Ú©Ù…Ú© Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø² Transformers) Ù…ØªÙ† ÛŒÚ© ÙØ§ÛŒÙ„ Word Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ØŒ Ø¢Ù† Ø±Ø§ Ø®Ù„Ø§ØµÙ‡ØŒ ØªØ±Ø¬Ù…Ù‡ ÛŒØ§ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….\n",
    "\n",
    "ğŸ› ï¸ **Ø³Ø±ÙØµÙ„â€ŒÙ‡Ø§:**  \n",
    "1. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Word  \n",
    "2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†  \n",
    "3. Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒØŒ ØªØ±Ø¬Ù…Ù‡ØŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ)  \n",
    "4. Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64550b1",
   "metadata": {},
   "source": [
    "## 1. Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ca704",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-docx transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420244c",
   "metadata": {},
   "source": [
    "## 2. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Word Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from docx import Document\n",
    "\n",
    "uploaded = files.upload()\n",
    "text = \"\"\n",
    "\n",
    "for fn in uploaded:\n",
    "    if fn.endswith(\".docx\"):\n",
    "        doc = Document(fn)\n",
    "        text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "        print(\"âœï¸ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡:\")\n",
    "        print(text[:500])\n",
    "        break\n",
    "\n",
    "if not text:\n",
    "    print(\"âš ï¸ ÙØ§ÛŒÙ„ Word Ù…Ø¹ØªØ¨Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb0738",
   "metadata": {},
   "source": [
    "## 3. Ø§Ù†ØªØ®Ø§Ø¨ Ø¹Ù…Ù„ÛŒØ§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda85bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Œ Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´:\")\n",
    "print(\"1 - Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ\")\n",
    "print(\"2 - ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\")\n",
    "print(\"3 - Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø±Ø³Ù…ÛŒâ€ŒØªØ±\")\n",
    "\n",
    "choice = input(\"Ø´Ù…Ø§Ø±Ù‡ Ø¹Ù…Ù„ÛŒØ§Øª Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71c51e",
   "metadata": {},
   "source": [
    "## 4. Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee78838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "if choice == \"1\":\n",
    "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "    result = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    print(\"\\nğŸ“„ Ø®Ù„Ø§ØµÙ‡ Ù…ØªÙ†:\")\n",
    "    print(result)\n",
    "\n",
    "elif choice == \"2\":\n",
    "    translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fa-en\")\n",
    "    result = translator(text[:1000])[0]['translation_text']\n",
    "    print(\"\\nğŸŒ ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ:\")\n",
    "    print(result)\n",
    "\n",
    "elif choice == \"3\":\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fa-en\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-fa-en\")\n",
    "    inputs = tokenizer(text[:500], return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
    "    reformulated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"\\nğŸª¶ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø±Ø³Ù…ÛŒ:\")\n",
    "    print(reformulated)\n",
    "\n",
    "else:\n",
    "    print(\"â›” Ø¹Ù…Ù„ÛŒØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
